FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=6 15 3 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (6, 5, 5.00000000000000000000e-01) (6, 5, 5.00000000000000000000e-01) (6, 5, 5.00000000000000000000e-01) (6, 5, 5.00000000000000000000e-01) (6, 5, 5.00000000000000000000e-01) (6, 5, 5.00000000000000000000e-01) (6, 5, 5.00000000000000000000e-01) (6, 5, 5.00000000000000000000e-01) (6, 5, 5.00000000000000000000e-01) (6, 5, 5.00000000000000000000e-01) (6, 5, 5.00000000000000000000e-01) (6, 5, 5.00000000000000000000e-01) (6, 5, 5.00000000000000000000e-01) (6, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) (15, 5, 5.00000000000000000000e-01) (15, 5, 5.00000000000000000000e-01) (0, 5, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, 1.07875478267669677734e+00) (1, 1.02884042263031005859e+00) (2, 1.14740991592407226562e+00) (3, 1.00590705871582031250e+00) (4, 1.14278650283813476562e+00) (5, 1.01505041122436523438e+00) (0, 1.08077120780944824219e+00) (1, 1.17366063594818115234e+00) (2, 1.11761963367462158203e+00) (3, 1.08181822299957275391e+00) (4, 1.04556977748870849609e+00) (5, 1.00899970531463623047e+00) (0, 1.13912320137023925781e+00) (1, 1.03421127796173095703e+00) (2, 1.18561244010925292969e+00) (3, 1.09067559242248535156e+00) (4, 1.16766166687011718750e+00) (5, 1.05232584476470947266e+00) (0, 1.05118346214294433594e+00) (1, 1.08340394496917724609e+00) (2, 1.15807783603668212891e+00) (3, 1.11943554878234863281e+00) (4, 1.00791084766387939453e+00) (5, 1.11587417125701904297e+00) (0, 1.07402396202087402344e+00) (1, 1.17959630489349365234e+00) (2, 1.04168069362640380859e+00) (3, 1.02310585975646972656e+00) (4, 1.19133234024047851562e+00) (5, 1.17923831939697265625e+00) (0, 1.19415056705474853516e+00) (1, 1.07077288627624511719e+00) (2, 1.00876617431640625000e+00) (3, 1.14224517345428466797e+00) (4, 1.07716727256774902344e+00) (5, 1.15204143524169921875e+00) (0, 1.15778505802154541016e+00) (1, 1.15843069553375244141e+00) (2, 1.12638652324676513672e+00) (3, 1.07609546184539794922e+00) (4, 1.04093968868255615234e+00) (5, 1.17245042324066162109e+00) (0, 1.08558249473571777344e+00) (1, 1.18055617809295654297e+00) (2, 1.00735008716583251953e+00) (3, 1.07188153266906738281e+00) (4, 1.07191908359527587891e+00) (5, 1.17550027370452880859e+00) (0, 1.12469458580017089844e+00) (1, 1.12358963489532470703e+00) (2, 1.05959224700927734375e+00) (3, 1.08346307277679443359e+00) (4, 1.04372096061706542969e+00) (5, 1.06799042224884033203e+00) (0, 1.00003278255462646484e+00) (1, 1.11823213100433349609e+00) (2, 1.04827427864074707031e+00) (3, 1.04220080375671386719e+00) (4, 1.14182770252227783203e+00) (5, 1.04029238224029541016e+00) (0, 1.02212667465209960938e+00) (1, 1.13666284084320068359e+00) (2, 1.11155235767364501953e+00) (3, 1.03138017654418945312e+00) (4, 1.07959938049316406250e+00) (5, 1.18921637535095214844e+00) (0, 1.18391335010528564453e+00) (1, 1.03807508945465087891e+00) (2, 1.14833164215087890625e+00) (3, 1.11098659038543701172e+00) (4, 1.11465775966644287109e+00) (5, 1.18976461887359619141e+00) (0, 1.08412563800811767578e+00) (1, 1.00093567371368408203e+00) (2, 1.17100548744201660156e+00) (3, 1.09196305274963378906e+00) (4, 1.07330465316772460938e+00) (5, 1.04361331462860107422e+00) (0, 1.06815147399902343750e+00) (1, 1.19849729537963867188e+00) (2, 1.16769659519195556641e+00) (3, 1.12823152542114257812e+00) (4, 1.08264505863189697266e+00) (5, 1.01210677623748779297e+00) (6, 1.19671928882598876953e+00) (7, 1.08316516876220703125e+00) (8, 1.13082706928253173828e+00) (9, 1.04567849636077880859e+00) (10, 1.12585330009460449219e+00) (11, 1.07334697246551513672e+00) (12, 1.08645808696746826172e+00) (13, 1.14847052097320556641e+00) (14, 1.01070368289947509766e+00) (15, 1.19850862026214599609e+00) (16, 1.18034255504608154297e+00) (17, 1.09079027175903320312e+00) (18, 1.18840956687927246094e+00) (19, 1.16494059562683105469e+00) (20, 1.12935328483581542969e+00) (6, 1.13742589950561523438e+00) (7, 1.07661688327789306641e+00) (8, 1.04470598697662353516e+00) (9, 1.12787508964538574219e+00) (10, 1.16123509407043457031e+00) (11, 1.04612910747528076172e+00) (12, 1.09956884384155273438e+00) (13, 1.05388844013214111328e+00) (14, 1.11992084980010986328e+00) (15, 1.14367222785949707031e+00) (16, 1.12252700328826904297e+00) (17, 1.11910283565521240234e+00) (18, 1.11205518245697021484e+00) (19, 1.05145370960235595703e+00) (20, 1.00244343280792236328e+00) 
